# Translation Model
Experimenting with different architectures in deep learning for Translation

# Data
<p> We are trining the model with English-Telugu [data](https://drive.google.com/file/d/1xrD9bL78mbxpp-DdOw1EHhz1nzin_6dX/view), data has lot of unwanted and other language characters which needs to be pre processed</p>

# Model
## Base Model
 <p>Simple encoder-decoder with LSTM are used we are able to reach 0.4 BLEU score and loss upto 2.5 </p>
    
    ![Sample Text](images/sample_training_text.png)
    ![Loss](images/loss.png)
    ![Score](https://github.com/hemanthyernagula/translation/blob/experiment/images/BLEU%20score.png)
    ![Weights](images/weights.png)
    ![Bias](images/Bias.png)